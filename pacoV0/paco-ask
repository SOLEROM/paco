#!/usr/bin/env python3
"""
paco-ask - Ask LLM a question about your project
Usage: paco-ask <project> <question>
"""

import sys
import argparse
from paco_lib import (
    init_paco_dirs, 
    build_context_for_llm, 
    call_ollama,
    check_prompt_size
)


def main():
    parser = argparse.ArgumentParser(
        description="Ask PACO a question about your project"
    )
    parser.add_argument("project", help="Project name")
    parser.add_argument("question", help="Your question")
    parser.add_argument(
        "--model",
        default="llama3.2",
        help="Ollama model to use (default: llama3.2)"
    )
    
    args = parser.parse_args()
    
    # Initialize PACO dirs
    init_paco_dirs()
    
    print(f"ðŸ¤” Consulting knowledge about '{args.project}'...")
    
    # Build context
    context = build_context_for_llm(args.project)
    
    # Check prompt size
    within_limit, size_kb = check_prompt_size(context)
    if not within_limit:
        print(f"âš  Warning: Context size ({size_kb:.1f}KB) exceeds recommended limit", 
              file=sys.stderr)
    
    # Build prompt
    system_prompt = """You are PACO, a personal productivity assistant.
Help the user with practical advice about their project.
Be concise, actionable, and specific.
Base your answer on the project context provided."""
    
    user_prompt = f"""Project Context:

{context}

Question: {args.question}"""
    
    # Call LLM
    print("ðŸ’­ Thinking...")
    response = call_ollama(user_prompt, model=args.model, system_prompt=system_prompt)
    
    print("\n" + "="*60)
    print(response)
    print("="*60)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nCancelled.")
        sys.exit(1)
    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)
